{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "\n",
    "if physical_devices:\n",
    "    # Restrict Tensorflow to only use the first GPU\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "        tf.config.experimental.set_visible_devices(physical_devices[0], 'GPU')   \n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(physical_devices), \"Physical GPUs, \", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        #Visible devices must be set before GPUs have been initialized.\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from numpy import asarray\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense,MaxPool2D,Flatten,Dropout\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "import os\n",
    "import numpy as np\n",
    "import os.path\n",
    "import json\n",
    "import random\n",
    "\n",
    "from os import path\n",
    "from matplotlib import pyplot, cm, patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_size=16):\n",
    "        self.x = np.load('X_train.npy', mmap_mode='r')\n",
    "        self.y = np.load('Y_train.npy', mmap_mode='r')\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index * self.batch_size: (index+1)*self.batch_size], self.y[index * self.batch_size: (index+1)*self.batch_size]\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.x.shape[0] / self.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Training sample size: {}\".format(trainPct))\n",
    "\n",
    "\n",
    "models = Sequential()\n",
    "\n",
    "\n",
    "# Keras model with two hidden layer with 10 neurons each \n",
    "models.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(512,512,1),activation='relu',padding='same'))    # Input layer => input_shape should be explicitly designated\n",
    "models.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "models.add(Dropout(0.3))\n",
    "\n",
    "models.add(Conv2D(filters=128,kernel_size=(4,4),activation='relu',padding='same'))    # Input layer => input_shape should be explicitly designated\n",
    "models.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "models.add(Dropout(0.2))\n",
    "\n",
    "models.add(Conv2D(filters=12,kernel_size=(4,4),activation='relu',padding='same'))    # Input layer => input_shape should be explicitly designated\n",
    "models.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "models.add(Dropout(0.2))\n",
    "\n",
    "models.add(Conv2D(filters=32,kernel_size=(4,4),activation='relu',padding='same'))    # Input layer => input_shape should be explicitly designated\n",
    "models.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "models.add(Dropout(0.1))\n",
    "\n",
    "models.add(Conv2D(filters=64,kernel_size=(4,4),activation='relu',padding='same'))    # Input layer => input_shape should be explicitly designated\n",
    "models.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "models.add(Dropout(0.3))\n",
    "\n",
    "models.add(Conv2D(filters=128,kernel_size=(4,4),activation='relu',padding='same'))    # Input layer => input_shape should be explicitly designated\n",
    "models.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "models.add(Dropout(0.1))\n",
    "\n",
    "models.add(Conv2D(filters=64,kernel_size=(4,4),activation='relu',padding='same'))    # Input layer => input_shape should be explicitly designated\n",
    "models.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "models.add(Dropout(0.1))\n",
    "\n",
    "models.add(Conv2D(filters=32,kernel_size=(4,4),activation='relu',padding='same'))    # Input layer => input_shape should be explicitly designated\n",
    "models.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "models.add(Dropout(0.2))\n",
    "\n",
    "models.add(Conv2D(filters=64,kernel_size=(4,4),activation='relu',padding='same'))    # Input layer => input_shape should be explicitly designated\n",
    "models.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "models.add(Dropout(0.3))\n",
    "\n",
    "models.add(Flatten())\n",
    "models.add(Dense(512,activation='relu'))\n",
    "models.add(Dense(128,activation='relu'))\n",
    "models.add(Dense(64,activation='relu'))\n",
    "models.add(Dense(32,activation='relu'))\n",
    "models.add(Dense(4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mse']) \n",
    "models.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "generator = DataGenerator()\n",
    "models.fit_generator(generator ,epochs = 10,verbose =10)\n",
    "\n",
    "                # actual figure of metrics computed\n",
    "    \n",
    "class EvalDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_size=16):\n",
    "        self.x = np.load('X_test.npy', mmap_mode='r')\n",
    "        self.y = np.load('Y_test.npy', mmap_mode='r')\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index * self.batch_size: (index+1)*self.batch_size], self.y[index * self.batch_size: (index+1)*self.batch_size]\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.x.shape[0] / self.batch_size))\n",
    "\n",
    "eval_generator = EvalDataGenerator()\n",
    "results = models.evaluate_generator(eval_generator)\n",
    "print(\"Training before results for model\")\n",
    "print(models.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(path):\n",
    "    \n",
    "    # Get ref file\n",
    "    RefDs = pydicom.read_file(path)\n",
    "\n",
    "    # Load dimensions based on the number of rows, columns, and slices (along the Z axis)\n",
    "    ConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), 1)\n",
    "\n",
    "    # Load spacing values (in mm)\n",
    "    ConstPixelSpacing = (float(RefDs.PixelSpacing[0]), float(RefDs.PixelSpacing[1]), float(RefDs.SliceThickness))\n",
    "\n",
    "    x = np.arange(0.0, (ConstPixelDims[0]+1)*ConstPixelSpacing[0], ConstPixelSpacing[0])\n",
    "    y = np.arange(0.0, (ConstPixelDims[1]+1)*ConstPixelSpacing[1], ConstPixelSpacing[1])\n",
    "    z = np.arange(0.0, (ConstPixelDims[2]+1)*ConstPixelSpacing[2], ConstPixelSpacing[2])\n",
    "\n",
    "    # The array is sized based on 'ConstPixelDims'\n",
    "\n",
    "    X_data = np.zeros(1*512*512,dtype=\"float32\")\n",
    "    # X_data = []\n",
    "    X_data=np.reshape(X_data,(1,512,512))\n",
    "    new_array = np.zeros(ConstPixelDims, dtype=RefDs.pixel_array.dtype)\n",
    "\n",
    "    ds = pydicom.read_file(path,force=True)\n",
    "    # store the raw image data\n",
    "    ds.file_meta.TransferSyntaxUID = pydicom.uid.ImplicitVRLittleEndian\n",
    "    idx=0\n",
    "    new_array[:,:,idx] = ds.pixel_array\n",
    "    X_data[idx] = new_array[:,:,idx]\n",
    "\n",
    "\n",
    "    print(X_data.shape)\n",
    "    X_data=np.reshape(X_data,(1,512,512,1))\n",
    "    print(X_data.shape)\n",
    "    \n",
    "    tmp = X_data\n",
    "    tmp -= 0.0\n",
    "    tmp = tmp/4095.0 - 0.5\n",
    "    print(tmp.shape)\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=analyse('/media/ccta/a3ee3238-d74c-4a4f-9c7f-afc98e547c81/Ahmed Fawzi/NEW/ITAC STUDIES/S101/S101-00139.dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=models.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=((y+0.5)*513)-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=analyse('/media/ccta/a3ee3238-d74c-4a4f-9c7f-afc98e547c81/Ahmed Fawzi/NEW/ITAC STUDIES/S101/S101-00247.dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=models.predict(X)\n",
    "y=((y+0.5)*513)-2\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = np.load('X_test.npy', mmap_mode='r')\n",
    "\n",
    "# y=models.predict(X_pred)\n",
    "# # y=((y+0.5)*513)-2\n",
    "# # print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save('/media/ccta/a3ee3238-d74c-4a4f-9c7f-afc98e547c81/Ahmed Fawzi/NEW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('/media/ccta/a3ee3238-d74c-4a4f-9c7f-afc98e547c81/Ahmed Fawzi/NEW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = np.load('X_test.npy', mmap_mode='r')\n",
    "\n",
    "y=model.predict(X_pred)\n",
    "y=((y+0.5)*513)-2\n",
    "print(y)\n",
    "y=y.astype(int)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_act = np.load('Y_test.npy', mmap_mode='r')\n",
    "Y_act=((Y_act+0.5)*513)-2\n",
    "\n",
    "Y_act=Y_act.astype(int)\n",
    "print(Y_act\n",
    ")\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Y_act))\n",
    "print(y.size)\n",
    "print(Y_act[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ycsv=[]\n",
    "for i in range(len(Y_act)):\n",
    "    Ycsv.append(Y_act[i])\n",
    "    Ycsv.append(y[i])\n",
    "print(len(Ycsv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ycsv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "numpy.savetxt(\"DATA.csv\", Ycsv, delimiter=\",\",fmt='% 4d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
